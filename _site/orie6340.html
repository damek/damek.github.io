<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-22302910-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">General</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="code.html">Code</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="orie6300.html" class="current">ORIE&nbsp;6300</a></div>
<div class="menu-item"><a href="orie6340.html">ORIE&nbsp;6340</a></div>
<div class="menu-category">Links</div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=uGdPyZQAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
<div class="menu-item"><a href="https://github.com/COR-OPT">GitHub</a></div>
</td>
<td id="layout-content">
<h1><br /> ORIE 6340 Mathematics of Data Science</h1>
<h2>Announcements </h2>
<ul>
<li><p>Welcome to the class!</p>
</li>
</ul>
<h2>Instructor Information</h2>
<p><b>instructor:</b> Damek Davis<br />
<b>office hours:</b> M 1:30PM-2:30PM, and by appointment<br />
<b>office:</b> <a href="https://goo.gl/maps/XGboPFoYDPz" target=&ldquo;blank&rdquo;>Rhodes Hall 218</a> <br />
<b>email:</b> dsd95 at cornell.edu<br /></p>
<p><b>teaching assistant:</b> <a href="https://people.cam.cornell.edu/md825/" target=&ldquo;blank&rdquo;>Mateo Diaz</a><br />
<b>office hours:</b> W 4-5 PM <br />
<b>email:</b> md825 at cornell.edu<br /></p>
<p><b>Ed Discussions:</b> See canvas </p>
<h2>Meeting Times and Location</h2>
<p><b>lecture time:</b> Monday and Wednesday 11:25am - 12:40pm<br />
<b>lecture location:</b> Zoom (see canvas for links)<br /></p>
<h2>Course Description</h2>
<p>This course is an introduction to an emerging research area broadly described as &ldquo;Math of Data Science.&rdquo; This area is highly interdisciplinary, so acquiring the tools necessary to participate is usually an overwhelming, and unsystematic process. ORIE 6340 is an attempt to overcome the current state of affairs.</p>
<p>The topics of the course will include:</p>
<ul>
<li><p>Concentration of measure phenomena for random vectors and matrices (e.g., subGaussian vectors; McDiarmid; Lipschitz functions; empirical processes; Rademacher complexity);</p>
</li>
<li><p>Estimation in high dimensions:</p>
<ul>
<li><p>Convex Relaxations and Spectral Methods (e.g., SDPs; stochastic block model; max cut; compressive sensing)</p>
</li>
<li><p>Direct nonconvex optimization methods (e.g., first-order methods; low-rank matrix estimation: matrix sensing and completion)</p>
</li>
</ul>

</li>
</ul>
<p>Don't let the outline fool you: this is a lot of material. Much of the course will be based on the excellent lecture notes of <a href="https://people.math.ethz.ch/~abandeira/BandeiraSingerStrohmer-MDS-draft.pdf" target=&ldquo;blank&rdquo;>Bandeira-Singer-Strohmer.</a> Throughout the semester, I will augment these notes with alternative readings (research papers/textbooks) that I find useful (see Resources below).  Depending on how quickly we cover the material, we will transition to current research topics as we progress through the course. </p>
<h3>Resources</h3>
<p>I will assume working knowledge of linear algebra and probability, optimization, and algorithms. I will review necessary facts from optimization and probability, but the more you know about these topics, the better you will be prepared. To that end, you might make use of the following textbooks.</p>
<ul>
<li><p>Optimization</p>
<ul>
<li><p><a href="https://people.orie.cornell.edu/dsd95/teaching/orie6300/ORIE6300Fall2019notes.pdf" target=&ldquo;blank&rdquo;><i>My Lecture Notes for ORIE 6300</i></a></p>
</li>
<li><p><a href="https://sites.math.washington.edu/~rtr/papers/rtr169-VarAnalysis-RockWets.pdf" target=&ldquo;blank&rdquo;><i>Variational Analysis</i></a> <br /> 
Rockafellar and Wets </p>
</li>
<li><p><a href="https://link.springer.com/book/10.1007/b97650" target=&ldquo;blank&rdquo;><i>Nonsmooth Analysis and Control Theory</i></a> <br />
Clarke, Ledyaev, Stern, and Wolenski </p>
</li>
<li><p><a href="https://link.springer.com/book/10.1007/978-0-387-40065-5" target=&ldquo;blank&rdquo;><i>Numerical Optimization</i></a><br />
Nocedal and Wright</p>
</li>
<li><p><a href="http://web.stanford.edu/~boyd/cvxbook/" target=&ldquo;blank&rdquo;><i>Convex Optimization</i></a> <br />
Boyd and Vandenberghe</p>
</li>
<li><p><a href="https://www.springer.com/us/book/9780387295701" target=&ldquo;blank&rdquo;><i>Convex Analysis and Nonlinear Optimization</i></a><br />
Borwein and Lewis</p>
</li>
<li><p><a href="https://www.springer.com/us/book/9783319915777" target=&ldquo;blank&rdquo;><i>Lectures on Convex Optimization</i></a> <br />
Nesterov</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Probability and Statistics</p>
<ul>
<li><p><a href="https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.html" target=&ldquo;blank&rdquo;><i>High-Dimensional Probability: An Introduction with Applications in Data Science</i></a> <br /> 
Vershynin</p>
</li>
<li><p><a href="https://www.cambridge.org/core/books/highdimensional-statistics/8A91ECEEC38F46DAB53E9FF8757C7A4E" target=&ldquo;blank&rdquo;><i>High-Dimensional Statistics: A Non-Asymptotic Viewpoint</i></a> <br />
Wainwright</p>
</li>
<li><p><a href="https://www.amazon.com/Concentration-Inequalities-Nonasymptotic-Theory-Independence/dp/019876765X" target=&ldquo;blank&rdquo;><i>Concentration Inequalities: A Nonasymptotic Theory of Independence</i></a><br /> 
Boucheron, Lugosi, and Massart </p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Statistical Learning </p>
<ul>
<li><p><a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/" target=&ldquo;blank&rdquo;><i>Understanding Machine Learning: From Theory to Algorithms</i></a> <br />
Shalev-Shwartz and Ben-David</p>
</li>
</ul>

</li>
</ul>
<h3>Requirements and Grading</h3>
<p>Grading Component: The grade will be based on two components:</p>
<ul>
<li><p>(40%) There will be (approximately) three homework assignments (To be uploaded). </p>
</li>
<li><p>(60%) There will be a final project (completed individually or in groups of two), which may either be a literature review or a research project based on topics similar to those mentioned in the course. Ideally, projects should be highly correlated with your own research interests. </p>
<ul>
<li><p>Initial Project Proposal: <b>Due Wednesday March 13th</b></p>
</li>
<li><p>Final Report:  <b>Due Monday May 6th</b></p>
</li>
<li><p>Presentation: <b>Last Week of Class</b></p>
</li>
</ul>

</li>
</ul>
<h3>Collaboration</h3>
<p>Cornellâ€™s Code of Academic Integrity can be found at <a href="cuinfo.cornell.edu/Academic/AIC.html" target=&ldquo;blank&rdquo;>cuinfo.cornell.edu/Academic/AIC.html</a>.</p>
<p>You may work together on problem sets, but you must write up your own solutions AND acknowledge those with whom you discussed the problem. You must also cite any resources which helped you obtain your solutions.</p>
<h2>Problem Sets </h2>
<h2>Lectures </h2>
<ul>
<li><p>Lecture Videos are posted on Canvas.</p>
</li>
<li><p>See Canvas&gt;Files for links to lecture PDFs and references.</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
