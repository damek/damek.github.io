---
layout: default
title: Damek Davis
---
# Damek Davis

[Publications](#publications) | [Research](research.html) | [CV](cv.pdf) | [Twitter](https://twitter.com/damekdavis) | [Github (current)](https://github.com/damek) | [Github (old)](https://github.com/COR-OPT) | [Google Scholar](https://scholar.google.com/citations?user=uGdPyZQAAAAJ&hl=en)


I'm an Associate Professor in Wharton's Department of Statistics and Data Science. I was previously an Associate Professor at Cornell ORIE, an NSF Postdoctoral Fellow, and a PhD student in Math at UCLA under Wotao Yin (Alibaba) and Stefano Soatto (AWS AI).

**Interests.** Optimization and machine learning.

**Selected Works.** I recently developed exponential of accelerations <a href="https://x.com/damekdavis/status/1841596498204880924">gradient descent</a>, <a href="https://twitter.com/damekdavis/status/1596616542396944384">semismooth Newton</a>, and <a href="https://twitter.com/damekdavis/status/1682737261727866882?s=20">the subgradient method</a>. Read more about my research [here](research.html).


**Selected Awards.** I received a <a href="https://sloan.org/fellowships/">Sloan Research Fellowship in Mathematics</a>, an <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2047637">NSF CAREER Award</a>, and the <a href="https://www.siam.org/prizes-recognition/activity-group-prizes/detail/siag-opt-best-paper-prize">SIAM Activity Group on Optimization Best Paper Prize</a>. 

**Students.** I've advised 5 PhD students. If you are a Penn student and wish to discuss advising/collaboration, send me a concise, informative email to set up a meeting.


*Current*: [Tao Jiang](https://taotolojiang.github.io/) (Cornell) → Meta (Postdoc) 

*Graduated PhD Students at Cornell*: 
- [Liwei Jiang](https://liwei-jiang97.github.io/) →  Purdue (Assistant Professor)
- [Vasilis Charisopoulos](https://vchariso.gitlab.io/) → UW, Seattle (Assistant Professor)
- [Mateo Díaz](https://mateodd25.github.io/) → Johns Hopkins University (Assistant Professor)
- [Ben Grimmer](https://www.ams.jhu.edu/~grimmer/) → Johns Hopkins University (Assistant Professor)


**Teaching.** I'm teaching [STAT 4830: "Optimization in PyTorch"](STAT-4830) in Spring 2025.


**Service.** I am currently an associate editor at <a href="https://www.springer.com/journal/10107">Mathematical Programming</a> and <a href="https://www.springer.com/journal/10208">Foundations of Computational Mathematics</a>.

Please use [my email](mailto:damek@wharton.upenn.edu) sparingly for correspondence related to research questions, teaching, or other professional inquiries. 

## Publications

[Preprints](#preprints) | [Conference papers](#conference-papers) | [Journal papers](#journal-papers) | [Book chapters](#book-chapters) | [Expository](#expository) | [Reports](#technical-reports)

### Preprints


[Gradient descent with adaptive stepsize converges (nearly) linearly under fourth-order growth](https://arxiv.org/abs/2409.19791)
Damek Davis, Dmitriy Drusvyatskiy, Liwei Jiang
Manuscript (2024)


###  Conference papers 

[Aiming towards the minimizers: fast convergence of SGD for overparametrized problems](https://arxiv.org/abs/2306.02601)
Chaoyue Liu, Dmitriy Drusvyatskiy, Mikhail Belkin, Damek Davis, Yi-An Ma
NeurIPS (2023) 

[A gradient sampling method with complexity guarantees for Lipschitz functions in high and low dimensions](https://arxiv.org/abs/2112.06969) 
Damek Davis, Dmitriy Drusvyatskiy, Yin Tat Lee, Swati Padmanabhan, Guanghao Ye
NeurIPS (2022) 
*Oral Presentation (top ~1%)*

[High probability guarantees for stochastic convex optimization](http://proceedings.mlr.press/v125/davis20a.html) 
Damek Davis, Dmitriy Drusvyatskiy
In Conference on Learning Theory (2020)

[Global Convergence of EM Algorithm for Mixtures of Two Component Linear Regression](http://proceedings.mlr.press/v99/kwon19a.html) 
Jeongyeol Kwon, Wei Qian, Constantine Caramanis, Yudong Chen, and Damek Davis
Conference on Learning Theory (2019)

[The Sound of APALM Clapping: Faster Nonsmooth Nonconvex Optimization with Stochastic Asynchronous PALM](https://papers.nips.cc/paper/6428-the-sound-of-apalm-clapping-faster-nonsmooth-nonconvex-optimization-with-stochastic-asynchronous-palm) 
Damek Davis, Brent Edmunds, Madeleine Udell
Neural Information Processing Systems (2016) | [report](https://arxiv.org/abs/1604.00526) 

[Multiview Feature Engineering and Learning](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dong_Multi-View_Feature_Engineering_2015_CVPR_paper.pdf) 
Jingming Dong, Nikos Karianakis, Damek Davis, Joshua Hernandez, Jonathan Balzer and Stefano Soatto
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)

[Asymmetric sparse kernel approximations for large-scale visual search.](http://www.vision.cs.ucla.edu/papers/davisBS14.pdf) 
Damek Davis, Jonathan Balzer, Stefano Soatto
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014)

### Journal papers 

[Active manifolds, stratifications, and convergence to local minima in nonsmooth optimization](https://arxiv.org/abs/2108.11832) 
Damek Davis, Dmitriy Drusvyatskiy, Liwei Jiang
Foundations of Computational Mathematics (to appear)

[Stochastic optimization over proximally smooth sets](https://arxiv.org/abs/2002.06309) 
Damek Davis, Dmitriy Drusvyatskiy, Zhan Shi
SIAM Journal on Optimization (to appear)

[Computational Microscopy beyond Perfect Lenses](https://arxiv.org/abs/2306.11283)
Xingyuan Lu, Minh Pham, Elisa Negrini, Damek Davis, Stanley J. Osher, Jianwei Miao
Physical Review E (to appear) 

[Global Optimality of the EM Algorithm for Mixtures of Two-Component Linear Regressions](https://ieeexplore.ieee.org/document/10614292)
Jeongyeol Kwon, Wei Qian, Constantine Caramanis, Yudong Chen, Damek Davis, Nhat Ho: 
IEEE Transactions on Information Theory (2024)

[Clustering a Mixture of Gaussians with Unknown Covariance](https://arxiv.org/abs/2110.01602) 
Damek Davis, Mateo Diaz, Kaizheng Wang
Bernoulli (to appear)

[Asymptotic normality and optimality in nonsmooth stochastic approximation](https://arxiv.org/abs/2301.06632) 
Damek Davis, Dmitriy Drusvyatskiy, Liwei Jiang
The Annals of Statistics (to appear)
*[Second Place in INFORMS Optimization Society 2024 Student Paper Prize](https://connect.informs.org/optimizationsociety/prizes/students-prize/2024)*

[A nearly linearly convergent first-order method for nonsmooth functions with quadratic growth](https://arxiv.org/abs/2205.00064) 
Damek Davis, Liwei Jiang
Foundations of Computational Mathematics (to appear) | [code](https://github.com/COR-OPT/ntd.py) | [Twitter thread](https://twitter.com/damekdavis/status/1682389849167233027?s=20)

[Stochastic algorithms with geometric step decay converge linearly on sharp functions](https://arxiv.org/abs/1907.09547) 
Damek Davis, Dmitriy Drusvyatskiy, Vasileios Charisopoulos
Mathematical Programming (to appear) | [code](https://github.com/COR-OPT/GeomStepDecay) 

[A superlinearly convergent subgradient method for sharp semismooth problems](https://arxiv.org/abs/2201.04611) 
Vasileios Charisopoulos, Damek Davis
Mathematics of Operations Research (2023) | [code](https://github.com/COR-OPT/SuperPolyak.py) | [Twitter Thread](https://twitter.com/damekdavis/status/1596616542396944384)

[Escaping strict saddle points of the Moreau envelope in nonsmooth optimization](https://arxiv.org/abs/2106.09815) 
Damek Davis, Mateo Díaz, Dmitriy Drusvyatskiy
SIAM Journal on Optimization (2022)

[Variance reduction for root-finding problems](https://link.springer.com/article/10.1007/s10107-021-01758-4) 
Damek Davis
Mathematical Programming (to appear)

[Conservative and semismooth derivatives are equivalent for semialgebraic maps](https://arxiv.org/abs/2102.08484) 
Damek Davis, Dmitriy Drusvyatskiy
Set-Valued and Variational Analysis (to appear)

[From low probability to high confidence in stochastic convex optimization](https://arxiv.org/abs/1907.13307) 
Damek Davis, Dmitriy Drusvyatskiy, Lin Xiao, Junyu Zhang
Journal of Machine Learning Research (to appear)

[Proximal methods avoid active strict saddles of weakly convex functions](https://arxiv.org/abs/1912.07146) 
Damek Davis, Dmitriy Drusvyatskiy
Foundations of Computational Mathematics (2021)

[Low-rank matrix recovery with composite optimization: good conditioning and rapid convergence](https://arxiv.org/abs/1904.10020) 
Vasileios Charisopoulos, Yudong Chen, Damek Davis, Mateo Díaz, Lijun Ding, Dmitriy Drusvyatskiy
Foundations of Computational Mathematics (to appear) | [code](https://github.com/COR-OPT/CompOpt-LowRankMatrixRecovery)

[Composite optimization for robust rank one bilinear sensing](https://academic.oup.com/imaiai/advance-article-abstract/doi/10.1093/imaiai/iaaa027/5936039) 
Vasileios Charisopoulos, Damek Davis, Mateo Diaz, Dmitriy Drusvyatskiy
IMA Journal on Information and Inference (2020) | [code](https://github.com/COR-OPT/RobustBlindDeconv)

[Graphical Convergence of Subgradients in Nonconvex Optimization and Learning](https://arxiv.org/abs/1810.07590) 
Damek Davis, Dmitriy Drusvyatskiy
Mathematics of Operations Research (to appear)

[Proximally Guided Stochastic Subgradient Method for Nonsmooth, Nonconvex Problems.](https://arxiv.org/abs/1707.03505) 
Damek Davis, Benjamin Grimmer
SIAM Journal on Optimization (to appear) | [code](https://github.com/COR-OPT/PGSG/blob/master/Interactive-PGSG.ipynb)

[Trimmed Statistical Estimation via Variance Reduction](https://doi.org/10.1287/moor.2019.0992) 
Aleksandr Aravkin, Damek Davis
Mathematics of Operations Research (2019) | [video](https://www.youtube.com/watch?v=_HNQtTGDRNg)

[Stochastic subgradient method converges on tame functions.](https://arxiv.org/abs/1804.07795) 
Damek Davis, Dmitriy Drusvyatskiy, Sham Kakade, Jason D. Lee
Foundations of Computational Mathematics (to appear)
*Finalist for the Best Paper Prize for Young Researchers in Continuous Optimization (2019)*

[The nonsmooth landscape of phase retrieval](https://academic.oup.com/imajna/article-abstract/40/4/2652/5684995) 
Damek Davis, Dmitriy Drusvyatskiy, Courtney Paquette
IMA Journal on Numerical Analysis (2018)

[Stochastic model-based minimization of weakly convex functions.](https://arxiv.org/abs/1803.06523) 
Damek Davis, Dmitriy Drusvyatskiy
SIAM Journal on Optimization (2019) | [blog](http://ads-institute.uw.edu//blog/2018/04/02/sgd-weaklyconvex/)
This is the combination of the two arXiv preprints  [arXiv:1802.02988](https://arxiv.org/abs/1802.02988)  and  [arXiv:1803.06523](https://arxiv.org/abs/1803.06523) 
Supplementary technical note:  [Complexity of finding near-stationary points of convex functions stochastically](https://arxiv.org/abs/1802.08556) 
Related report on nonsmooth nonconvex mirror descent  [Stochastic model-based minimization under high-order growth](http://www.optimization-online.org/DB_HTML/2018/07/6690.html)  (2018)
*INFORMS Optimization Society Young Researchers Prize (2019)*

[Subgradient methods for sharp weakly convex functions](https://link.springer.com/article/10.1007/s10957-018-1372-8) 
Damek Davis, Dmitriy Drusvyatskiy, Kellie J. MacPhee, Courtney Paquette
Journal of Optimization Theory and Applications (2018)

[Forward-Backward-Half Forward Algorithm for Solving Monotone Inclusions](https://doi.org/10.1137/17M1120099) 
Luis M. Briceño-Arias, Damek Davis
SIAM Journal on Optimization (2018)

[Convergence rate analysis of the forward-Douglas-Rachford splitting scheme.](https://doi.org/10.1137/140992291) 
Damek Davis
SIAM Journal on Optimization (2015)

[Convergence rate analysis of primal-dual splitting schemes](https://arxiv.org/abs/1408.4419) 
Damek Davis
SIAM Journal on Optimization (2015)

[Faster convergence rates of relaxed Peaceman-Rachford and ADMM under regularity assumptions](http://pubsonline.informs.org/doi/full/10.1287/moor.2016.0827) 
Damek Davis, Wotao Yin
Mathematics of Operations Research (2016)

[A Three-Operator Splitting Scheme and its Optimization Applications.](https://link.springer.com/article/10.1007/s11228-017-0421-z) 
Damek Davis, Wotao Yin
Set-Valued and Variational Analysis (2017) | [code](https://damek.github.io/ThreeOperators.html) | [slides](https://damek.github.io/ThreeOperators3-online.pdf) 

[Beating level-set methods for 5D seismic data interpolation: a primal-dual alternating approach](http://ieeexplore.ieee.org/document/7906537) 
Rajiv Kumar, Oscar López, Damek Davis, Aleksandr Y. Aravkin, Felix J. Herrmann
IEEE Transactions on Computational Imaging (2017)

[Tactical Scheduling for Precision Air Traffic Operations: Past Research and Current Problems](http://arc.aiaa.org/doi/full/10.2514/1.I010119) 
Douglas R. Isaacson, Alexander V. Sadovsky, Damek Davis
Journal of Aerospace Information Systems, April, Vol. 11, No. 4 : pp. 234-257

[Efficient computation of separation-compliant speed advisories for air traffic arriving in terminal airspace.](http://dynamicsystems.asmedigitalcollection.asme.org/article.aspx?articleid=1838670) 
Alexander V. Sadovsky, Damek Davis, Douglas R. Isaacson.
Journal of Dynamic Systems Measurement and Control 136(4), 041027 (2014)

[Separation-compliant, optimal routing and control of scheduled arrivals in a terminal airspace.](http://www.aviationsystemsdivision.arc.nasa.gov/publications/2013/Transportation_Research_Part_C_2013_Sadovsky.pdf) 
Alexander V. Sadovsky, Damek Davis, and Douglas R. Isaacson.
Transportation Research Part C: Emerging Technologies 37 (2013): 157-176

[Factorial and Noetherian Subrings of Power Series Rings.](http://www.ams.org/journals/proc/2011-139-03/S0002-9939-2010-10620-2/) 
Damek Davis, Daqing Wan
Proceedings of the American Mathematical Society 139 (2011), no. 3, 823-834

### Book chapters
[Convergence rate analysis of several splitting schemes](https://link.springer.com/chapter/10.1007/978-3-319-41589-5_4) 
Damek Davis, Wotao Yin
Splitting Methods in Communication and Imaging, Science and Engineering (2017) 
[video](https://www.youtube.com/watch?v=XDI9UbUkUz4) | [slides](https://damek.github.io/INFORMS_Presentation_Final.pdf) | [summary](https://damek.github.io/OStoday0515.pdf)
*Winner of the* [2014 INFORMS optimization society best student paper prize.](https://www.informs.org/Community/Optimization-Society/Optimization-Society-Prizes/Student-Paper-Prize/2014)

### Expository 

[A Short Course on Convex Analysis and First-Order Methods](https://damek.github.io/teaching/orie6300/ORIE6300Fall2023notes.pdf) 
Damek Davis
Manuscript (2023)

[Subgradient methods under weak convexity and tame geometry](research/papers/ViewsAndNews-28-1.pdf) 
Damek Davis, Dmitriy Drusvyatskiy
SIAG/OPT News and Views (2020)

[Convergence Rate Analysis of Several Splitting Schemes](https://damek.github.io/OStoday0515.pdf) 
Damek Davis
INFORMS OS Today (2015)

### Technical reports 
[A linearly convergent Gauss-Newton subgradient method for ill-conditioned problems](https://arxiv.org/abs/2212.13278)
Damek Davis, Tao Jiang
Technical report (2023) | [code](https://github.com/COR-OPT/GaussNewtonPolyak.py)

[Stochastic model-based minimization under high-order growth.](http://www.optimization-online.org/DB_HTML/2018/07/6690.html) 
Damek Davis, Dmitriy Drusvyatskiy, Kellie J. MacPhee
Technical Report (2018)

[An \(O(n\log(n))\) algorithm for projecting onto the ordered weighted \(\ell_1\) norm ball](http://www.optimization-online.org/DB_FILE/2015/03/4851.pdf) 
Damek Davis
UCLA CAM report 15-32 (2015) | [code](https://damek.github.io/OWLBall.html) 

[SMART: The Stochastic Monotone Aggregated Root-Finding Algorithm.](https://arxiv.org/abs/1601.00698) 
Damek Davis
Manuscript (2015) [ [slides](https://damek.github.io/Talks/SMART.pdf) ] [ [video](https://vimeo.com/156600995) ]

